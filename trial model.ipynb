{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "%pip install seaborn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "%pip install imbalanced-learn",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn import metrics\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import RandomOverSampler",
      "metadata": {
        "id": "E3cGLGocHue8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-3-aa79de504801>:2: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_csv('train.csv')",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoYrTl7cHz2A",
        "outputId": "6d0e45d5-eac5-40af-e78b-748d425aac2f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "df = df.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n",
      "metadata": {
        "id": "-1jyyKEfIN7Q",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-5-36aa8ff0286a>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df = df.replace({'yes':1, 'no':0, '?':'Others', 'others':'Others'})\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "ints = []\nobjects = []\nfloats = []\n\nfor col in df.columns:\n  if pd.api.types.is_integer_dtype(df[col]):\n    ints.append(col)\n  elif df[col].dtype == object:\n    objects.append(col)\n  else:\n    floats.append(col)\n\nfor i in ints:\n    print(i)",
      "metadata": {
        "id": "Wtrs1SkSIQKv",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "ID\nA1_Score\nA2_Score\nA3_Score\nA4_Score\nA5_Score\nA6_Score\nA7_Score\nA8_Score\nA9_Score\nA10_Score\njaundice\naustim\nused_app_before\nClass/ASD\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "ints.remove('ID')\nints.remove('Class/ASD')",
      "metadata": {
        "id": "_8HUmuWnIRnR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "# Convert the data to long-form using melt\ndf_melted = df.melt(id_vars=['ID', 'Class/ASD'], value_vars=ints, var_name='col', value_name='value')\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GlWSKWy0JR07",
        "outputId": "52fb3c5a-2575-43c1-dfed-9c7ec9604575",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "# This functions make groups by taking\n# the age as a parameter\ndef convertAge(age):\n    if age < 4:\n        return 'Toddler'\n    elif age < 12:\n        return 'Kid'\n    elif age < 18:\n        return 'Teenager'\n    elif age < 40:\n        return 'Young'\n    else:\n        return 'Senior'\n\ndf['ageGroup'] = df['age'].apply(convertAge)\n",
      "metadata": {
        "id": "XZ9kZWf_IbHK",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "def add_feature(data):\n\n  # Creating a column with all values zero\n  data['sum_score'] = 0\n  for col in data.loc[:,'A1_Score':'A10_Score'].columns:\n\n    # Updating the 'sum_score' value with scores\n    # from A1 to A10\n    data['sum_score'] += data[col]\n\n  # Creating a random data using the below three columns\n  data['ind'] = data['austim'] + data['used_app_before'] + data['jaundice']\n\n  return data\n\ndf = add_feature(df)\n",
      "metadata": {
        "id": "fso8ebz4Idut",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "# Applying log transformations to remove the skewness of the data.\ndf['age'] = df['age'].apply(lambda x: np.log(x))\n",
      "metadata": {
        "id": "gDTluzi1IgMV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "def encode_labels(data):\n    for col in data.columns:\n\n      # Here we will check if datatype\n      # is object then we will encode it\n      if data[col].dtype == 'object':\n        le = LabelEncoder()\n        data[col] = le.fit_transform(data[col])\n\n    return data\n\ndf = encode_labels(df)\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "id": "QB2QnUWSIiQ9",
        "outputId": "def258b4-b1f5-4aad-83b6-7773ca7870f2",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": "removal = ['ID', 'age_desc', 'used_app_before', 'austim']\nfeatures = df.drop(removal + ['Class/ASD'], axis=1)\ntarget = df['Class/ASD']\n",
      "metadata": {
        "id": "FbVG-30wIjas",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": "X_train, X_val, Y_train, Y_val = train_test_split(features, target, test_size = 0.2, random_state=10)\n\n# As the data was highly imbalanced we will balance it by adding repetitive rows of minority class.\nros = RandomOverSampler(sampling_strategy='minority',random_state=0)\nX, Y = ros.fit_resample(X_train,Y_train)\nX.shape, Y.shape\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oibiPTiTIk5H",
        "outputId": "e898b795-6870-41ca-976a-ea6425715e25",
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "((1028, 20), (1028,))"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": "# Normalizing the features for stable and fast training.\nscaler = StandardScaler()# standardises the features so that each feature contributes equally\nX = scaler.fit_transform(X)# fit calculates nesecarry statistics then transform transform them\nX_val = scaler.transform(X_val)# did not understand\n",
      "metadata": {
        "id": "biU0aEU6ImWD",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": "model =  XGBClassifier()\n\nmodel.fit(X, Y)\n    #we will use xgbclasssifier\nprint(f'{model} : ')\nprint('Training Accuracy : ', metrics.roc_auc_score(Y, model.predict(X)))\nprint('Validation Accuracy : ', metrics.roc_auc_score(Y_val, model.predict(X_val)))\n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRUr4237Inbn",
        "outputId": "91c2b85c-ae12-4d90-9f04-5ff7ca5bb214",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=None, ...) : \nTraining Accuracy :  1.0\nValidation Accuracy :  0.7257142857142856\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": "import joblib\n\n# Save the trained model to a file\njoblib.dump(model, 'xgb_model.pkl')\njoblib.dump(scaler, 'scaler.pkl')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "model.feature_names = list(X_train.columns.values)\nprint(model.feature_names)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score', 'age', 'gender', 'ethnicity', 'jaundice', 'contry_of_res', 'result', 'relation', 'ageGroup', 'sum_score', 'ind']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 18
    }
  ]
}