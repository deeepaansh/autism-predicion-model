{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import joblib\nimport numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler\nfrom xgboost import XGBClassifier",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "model = joblib.load('xgb_model.pkl')\nscaler = joblib.load('scaler.pkl')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "input_array = np.array([1,1,1,1,1,1,1,0,1,1,25.06830214,1,1,1,1,1,0,13.99540321,3,1])\n\n# These are the original column names used during training (ensure they are correct)\ncolumns = ['ID','A1_Score','A2_Score','A3_Score','A4_Score','A5_Score','A6_Score','A7_Score','A8_Score','A9_Score','A10_Score','age','gender','ethnicity','jaundice','contry_of_res','result','age_desc','relation','Class/ASD']  # Replace with actual column names\n\n# Convert input array to a DataFrame with the same column names\nexpected_features = [\n    'A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', \n    'A5_Score', 'A6_Score', 'A7_Score', 'A8_Score', \n    'A9_Score', 'A10_Score', 'age', 'gender', \n    'ethnicity', 'jaundice', 'austim', 'contry_of_res', \n    'used_app_before', 'sum_score', 'ind', \n    'ageGroup']\n\ninput_df = pd.DataFrame([input_array], columns=columns)\ninput_df['austim'] = 0  # Default value\ninput_df['used_app_before'] = 0  # Default value\ninput_df['age_desc'] = 0  # Default value or a suitable placeholder\n\ndef convert_age(age):\n    \n    if age < 4:\n        return 'Toddler'\n    elif age < 12:\n        return 'Kid'\n    elif age < 18:\n        return 'Teenager'\n    elif age < 40:\n        return 'Young'\n    else:\n        return 'Senior'\n        \n\ninput_df['ageGroup'] = input_df['age'].apply(convert_age)\n\ninput_df = pd.get_dummies(input_df, columns=['ageGroup'], drop_first=True)\n\nfor feature in expected_features:\n    if feature not in input_df.columns:\n        input_df[feature] = 0 \n# Recreate `sum_score`\ninput_df['sum_score'] = input_df[['A1_Score', 'A2_Score', 'A3_Score', 'A4_Score', 'A5_Score', \n                                  'A6_Score', 'A7_Score', 'A8_Score', 'A9_Score', 'A10_Score']].sum(axis=1)\n\n #Recreate `ind` (using default values for 'austim' and 'used_app_before')\ninput_df['ind'] = input_df['jaundice'] + input_df['austim'] + input_df['used_app_before']\n\n# Drop unnecessary columns (if not needed for the model)\ninput_df = input_df.drop(columns=['ID','austim', 'used_app_before', 'age_desc','Class/ASD'])\n\n# Scale the input DataFrame\ninput_df_scaled = scaler.transform(input_df)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "prediction = model.predict(input_df_scaled)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "print(\"Prediction: \", prediction)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}